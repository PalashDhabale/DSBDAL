/*
    Problem Statement No. 05
Write a Scala Program to process a log file of a system and perform following analytics on the given dataset.
(I) Display the list of top 10 frequent hosts.
(II) Display the list of top 5 URLs or paths
(III) Display the number of unique Hosts

*/

val pathToDataSet = "/home/kali/DJABRJ/spark_pract/weblog.csv"

val df = spark.read.option("header", "true").option("inferSchema", "true")csv(pathToDataSet)


val topHosts = df.groupBy("IP").count().orderBy($"count".desc).limit(10)
val topUrls = df.groupBy("URL").count().orderBy($"count".desc).limit(5)
val uniqueHosts = df.select("IP").distinct().count()

println("Top 10 frequent hosts:")
topHosts.show(false)

println("\nTop 5 URLs or paths:")
topUrls.show(false)

println("\nNumber of unique Hosts:")
println(uniqueHosts)

val cleaned_df = df.filter($"IP".rlike("^\\d+\\.\\d+\\.\\d+\\.\\d+$"))

val topHosts_cleaned = cleaned_df.groupBy("IP").count().orderBy($"count".desc).limit(10)
val topUrls_cleaned = cleaned_df.groupBy("URL").count().orderBy($"count".desc).limit(5)
val uniqueHosts_cleaned = cleaned_df.select("IP").distinct().count()

println("Top 10 frequent hosts:")
topHosts_cleaned.show(false)

println("\nTop 5 URLs or paths:")
topUrls_cleaned.show(false)

println("\nNumber of unique Hosts:")
println(uniqueHosts_cleaned)

println("Number of bad row in the initial dataset: " + base_df.filter($"value".isNull).count())

val bad_rows_df = parsed_df.filter($"host".isNull || $"timestamp".isNull || $"path".isNull || $"status".isNull)
println("Number of bad rows: " + bad_rows_df.count())

val cleaned_df = parsed_df.na.drop()

println("The count of null value: " + cleaned_df.filter($"host".isNull || $"timestamp".isNull || $"path".isNull || $"status".isNull).count())
println("Before: " + parsed_df.count() + " | After: " + cleaned_df.count())

val logs_df = cleaned_df.withColumn("time", to_timestamp($"timestamp", "dd/MMM/yyyy:HH:mm:ss")).drop("timestamp").cache()

logs_df.printSchema()

logs_df.show(2)

logs_df.describe("status").show()

logs_df.groupBy("host").count().sort(desc("count")).show(10)

logs_df.groupBy("path").count().sort(desc("count")).show(5)

val unique_host_count = logs_df.select("host").distinct().count()
println("Number of unique Hosts: %d".format(unique_host_count))

val not_found_count = logs_df.filter($"status" === 404).count()
println("Count of 404 Response Codes: %d".format(not_found_count))
logs_df.filter($"status" === 404).show()


logs_df.filter($"status" === 404).groupBy("host").count().sort(desc("count")).show(25, truncate = false)

val unique_daily_hosts_count = logs_df.select("host", "day", "year").distinct().groupBy("day", "year").count().sort("year", "day").count()
println("Number of Unique Daily Hosts: %d".format(unique_daily_hosts_count))
