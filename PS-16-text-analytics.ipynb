{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cde5230-d0c2-49b6-a035-d2c32a4ed088",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Problem Statement No. 16 \n",
    "Consider the Amazon Alexa Reviews Dataset. This dataset consists of a nearly 3000 Amazon customer reviews (input \n",
    "text), star ratings, date of review, variant and feedback of various amazon Alexa products like Alexa Echo, Echo dots, \n",
    "Alexa Firesticks etc. Perform following operations on this dataset. \n",
    "(I) Remove all punctuations from review text. \n",
    "(II) Tokenize the review text into words. \n",
    "(III) Remove the Stopwords from the tokenized text. \n",
    "(IV) Perform stemming & lemmatization on the review text. \n",
    "(V) Perform the word vectorization on review text using Bag of Words technique. \n",
    "(VI) Create representation of Review Text by calculating Term Frequency and Inverse Document Frequency (TF-IDF)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1fe7bf82-fc8f-4443-820f-f0a7389aa542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e55dbe77-7cb6-4fa3-ac1b-a0509de604d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Alexa-Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "489e76ab-317f-4f5f-a4b8-73a32ee4878e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>5</td>\n",
       "      <td>29-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>I have been wanting one of these for a while n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>5</td>\n",
       "      <td>29-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Very nice!  I'm impressed - wish she had more ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Configuration: Fire TV Stick</td>\n",
       "      <td>Extremely easy to use! Switched away from dire...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>2</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Sound is terrible if u want good music too get...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>Love it. Added it to an upstairs bedroom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating       date                     variation  \\\n",
       "965        5  29-Jul-18              Charcoal Fabric    \n",
       "203        5  29-Jul-18              Charcoal Fabric    \n",
       "2371       5  30-Jul-18  Configuration: Fire TV Stick   \n",
       "806        2  30-Jul-18              Charcoal Fabric    \n",
       "2727       5  30-Jul-18                    Black  Dot   \n",
       "\n",
       "                                       verified_reviews  feedback  \n",
       "965   I have been wanting one of these for a while n...         1  \n",
       "203   Very nice!  I'm impressed - wish she had more ...         1  \n",
       "2371  Extremely easy to use! Switched away from dire...         1  \n",
       "806   Sound is terrible if u want good music too get...         0  \n",
       "2727           Love it. Added it to an upstairs bedroom         1  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea51d874-8970-4aa2-8186-8be31cd1e337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sometimes while playing a game, you can answer a question correctly but Alexa says you got it wrong and answers the same as you.  I like being able to turn lights on and off while away from home.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['verified_reviews'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2bad25bb-86af-45d8-a286-c811c86c75f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['verified_reviews'] = df['verified_reviews'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7dd10b1e-70e5-4ab3-90af-528356c89ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sometimes while playing a game, you can answer a question correctly but alexa says you got it wrong and answers the same as you.  i like being able to turn lights on and off while away from home.'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['verified_reviews'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "13831023-6313-4d65-8074-ec983f6847eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dee11f76-6dea-41e8-8810-f49582cd4097",
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "81e5c6a5-9fa5-43c7-86c0-3774c1f20444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "14c49045-fcea-4a75-a8be-53f4d5a0280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(data):\n",
    "    for char in punc:\n",
    "        data = data.replace(char,'')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "23cb5bdb-de47-4ca1-8e39-eb2c8b8b484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'i have a data . ,'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "573cd16f-af6f-4261-aa1f-6ec46f050d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i have a data  '"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punctuation(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ca624d64-7022-4d4d-98fa-e18c33cc2067",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['verified_reviews'] = df['verified_reviews'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4a0eb6ad-414c-4ad2-b1c4-cffc9a377f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['verified_reviews'] =df['verified_reviews'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "15890725-9eb5-4a7e-bd34-8419a5c51f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sometimes while playing a game you can answer a question correctly but alexa says you got it wrong and answers the same as you  i like being able to turn lights on and off while away from home'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['verified_reviews'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "01e87791-4000-43ac-9c95-28addf779db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a8008aca-3557-42c1-b063-7fae368f8b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1777a247-a0f0-4cb7-a2ab-571532dbf1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_word(data):\n",
    "    tokens = nltk.word_tokenize(data)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0a1edcf2-817d-4476-80bb-3c35d4336f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'have', 'a', 'data', '.', ',']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_word(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "924560ca-b65e-47e3-a52d-480e1763fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['verified_reviews'] = df['verified_reviews'].apply(tokenize_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4a72e99f-aed5-43bb-8839-d99ff17b4e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sometimes',\n",
       " 'playing',\n",
       " 'game',\n",
       " 'answer',\n",
       " 'question',\n",
       " 'correctly',\n",
       " 'alexa',\n",
       " 'says',\n",
       " 'got',\n",
       " 'wrong',\n",
       " 'answers',\n",
       " 'like',\n",
       " 'able',\n",
       " 'turn',\n",
       " 'lights',\n",
       " 'away',\n",
       " 'home']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['verified_reviews'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5136cc71-35df-4a3b-aff4-f834964fc4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a6c4387e-dd36-4c4e-9569-9785b00d5f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1ccf4dfb-d5ba-42ba-abfc-70a94acbff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['verified_reviews'] = df['verified_reviews'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0e43fa7d-4325-400a-b514-0fc4ae3c3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(data):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = data.split()\n",
    "    filtered_word = []\n",
    "    for word in words:\n",
    "        if word.lower() not in stop_words:\n",
    "            filtered_word.append(word)\n",
    "    filtered_text = ' '.join(filtered_word)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cb923de1-e023-49d3-91b7-c9be1826f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'hii i am a coder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "40c6fc07-bb70-4b57-a039-d9c99dbc8e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hii coder'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b5df9922-20d5-48ec-b0ab-966e5d839e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['verified_reviews'] = df['verified_reviews'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f47a27c2-66df-42a6-b0f5-bf0cf1db6ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sometimes playing game answer question correctly alexa says got wrong answers like able turn lights away home'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['verified_reviews'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "18784991-dbff-4467-8631-c6da2e3e9100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d65a624b-5596-4042-b2c2-d0ef679accfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0b1b2c37-f4a4-46f9-99dd-99bb03590531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_stemming(text):\n",
    "    stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    stemmed_text = ' '.join(stemmed_words)\n",
    "    return stemmed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "32919565-8a41-423e-85e9-33beca2c6e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'study studying studied' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6ee193dd-9e95-451b-8926-dbd303499ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    " words = nltk.word_tokenize(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "342e42ee-0dd3-4abc-aba2-2a260942f10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'studi studi studi'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform_stemming(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "924c128c-54fc-4088-9c5e-3846f1aebe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['verified_reviews'] = df['verified_reviews'].apply(perform_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dcb40fb8-3beb-4541-9b75-d86d2e05d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_net =  WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca3134ef-d9e5-4388-b04c-8ab8c3bcd108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85752cb5-d62d-48cf-b721-92bee99fc1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ' study studying come came coming ate eat'\n",
    "sentence_words = nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d9d4e0ab-3dd7-4caf-8c2e-c738eb0e7775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study study\n",
      "studying study\n",
      "come come\n",
      "came come\n",
      "coming come\n",
      "ate eat\n",
      "eat eat\n"
     ]
    }
   ],
   "source": [
    "for word in sentence_words:\n",
    "    print(word , word_net.lemmatize(word , pos = 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e5c0a536-7356-4aa9-88a4-76aa91d75942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "49b50132-cb0b-4400-af33-bf8a5e0fa363",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "982b682f-630d-42d9-9205-aa9b89bc2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = cov.fit_transform(df['verified_reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "80367459-99f5-49a6-992f-b74c43282d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f6057146-04f2-419b-bf7a-a0a858d56c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[15].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "14839cbe-cf4b-4255-9925-4abf9aeefcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f6798319-6310-4d08-9895-5e26f52f412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9951bd92-d48e-4bc3-900d-ecff9e54c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = tfidf.fit_transform(df['verified_reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "83563930-0c87-4802-9fbd-4722a45f7352",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_array = tfidf_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "eca7401a-9d8b-44fb-a39d-f05a8089ba72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "788ad862-d18c-45d9-9b36-cd53fb79942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_Set = tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fe017d89-8377-4b28-8e20-12afcf086b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['072318', '10', '100', ..., 'zzzz', 'zzzzzzz', 'útil'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5d50c88c-3b00-439e-9449-bb136b07b1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>072318</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>100x</th>\n",
       "      <th>1010</th>\n",
       "      <th>1030pm</th>\n",
       "      <th>11</th>\n",
       "      <th>1100sf</th>\n",
       "      <th>1220</th>\n",
       "      <th>...</th>\n",
       "      <th>youtubeit</th>\n",
       "      <th>yr</th>\n",
       "      <th>yup</th>\n",
       "      <th>zero</th>\n",
       "      <th>zigbe</th>\n",
       "      <th>zonkedout</th>\n",
       "      <th>zwave</th>\n",
       "      <th>zzzz</th>\n",
       "      <th>zzzzzzz</th>\n",
       "      <th>útil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3150 rows × 3315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      072318   10  100  1000  100x  1010  1030pm   11  1100sf  1220  ...  \\\n",
       "0        0.0  0.0  0.0   0.0   0.0   0.0     0.0  0.0     0.0   0.0  ...   \n",
       "1        0.0  0.0  0.0   0.0   0.0   0.0     0.0  0.0     0.0   0.0  ...   \n",
       "2        0.0  0.0  0.0   0.0   0.0   0.0     0.0  0.0     0.0   0.0  ...   \n",
       "3        0.0  0.0  0.0   0.0   0.0   0.0     0.0  0.0     0.0   0.0  ...   \n",
       "4        0.0  0.0  0.0   0.0   0.0   0.0     0.0  0.0     0.0   0.0  ...   \n",
       "...      ...  ...  ...   ...   ...   ...     ...  ...     ...   ...  ...   \n",
       "3145     0.0  0.0  0.0   0.0   0.0   0.0     0.0  0.0     0.0   0.0  ...   \n",
       "3146     0.0  0.0  0.0   0.0   0.0   0.0     0.0  0.0     0.0   0.0  ...   \n",
       "3147     0.0  0.0  0.0   0.0   0.0   0.0     0.0  0.0     0.0   0.0  ...   \n",
       "3148     0.0  0.0  0.0   0.0   0.0   0.0     0.0  0.0     0.0   0.0  ...   \n",
       "3149     0.0  0.0  0.0   0.0   0.0   0.0     0.0  0.0     0.0   0.0  ...   \n",
       "\n",
       "      youtubeit        yr  yup  zero  zigbe  zonkedout  zwave  zzzz  zzzzzzz  \\\n",
       "0           0.0  0.000000  0.0   0.0    0.0        0.0    0.0   0.0      0.0   \n",
       "1           0.0  0.000000  0.0   0.0    0.0        0.0    0.0   0.0      0.0   \n",
       "2           0.0  0.000000  0.0   0.0    0.0        0.0    0.0   0.0      0.0   \n",
       "3           0.0  0.335516  0.0   0.0    0.0        0.0    0.0   0.0      0.0   \n",
       "4           0.0  0.000000  0.0   0.0    0.0        0.0    0.0   0.0      0.0   \n",
       "...         ...       ...  ...   ...    ...        ...    ...   ...      ...   \n",
       "3145        0.0  0.000000  0.0   0.0    0.0        0.0    0.0   0.0      0.0   \n",
       "3146        0.0  0.000000  0.0   0.0    0.0        0.0    0.0   0.0      0.0   \n",
       "3147        0.0  0.000000  0.0   0.0    0.0        0.0    0.0   0.0      0.0   \n",
       "3148        0.0  0.000000  0.0   0.0    0.0        0.0    0.0   0.0      0.0   \n",
       "3149        0.0  0.000000  0.0   0.0    0.0        0.0    0.0   0.0      0.0   \n",
       "\n",
       "      útil  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "...    ...  \n",
       "3145   0.0  \n",
       "3146   0.0  \n",
       "3147   0.0  \n",
       "3148   0.0  \n",
       "3149   0.0  \n",
       "\n",
       "[3150 rows x 3315 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_idf = pd.DataFrame(tfidf_array, columns = word_Set)\n",
    "\n",
    "df_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af00ad2-5693-4b5d-aa6f-f092341cdbaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
